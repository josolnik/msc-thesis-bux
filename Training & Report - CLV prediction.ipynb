{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jo/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import utils\n",
    "import utils_bux\n",
    "import featuretools as ft\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE THE PIPELINE PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline parameters defined\n"
     ]
    }
   ],
   "source": [
    "show_report = True\n",
    "save_model = False\n",
    "\n",
    "# the timeframe of extracted users\n",
    "users_from = '2016-10-01'\n",
    "users_till = '2016-11-01'\n",
    "# users_till = '2017-09-30'\n",
    "cohort_size = 2000\n",
    "\n",
    "# the timeframe of extracted behavioral data\n",
    "interval = '1 week'\n",
    "\n",
    "# the type of the prediction problem\n",
    "# 'regression', 'binary classification', 'multiclass classification'\n",
    "prediction_problem_type = 'multiclass classification'\n",
    "\n",
    "# multiclass values\n",
    "medium_value = 5\n",
    "high_value = 50\n",
    "\n",
    "# number of the most important features to extract\n",
    "number_of_features = 20\n",
    "\n",
    "print(\"Pipeline parameters defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONNECT TO THE DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database\n"
     ]
    }
   ],
   "source": [
    "# connect to the vertica database, create a cursor\n",
    "cur = utils.connect_to_db()\n",
    "print(\"Connected to the database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILD ENTITY SET AND LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohorts entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohorts entity built\n"
     ]
    }
   ],
   "source": [
    "cohorts = utils_bux.build_cohorts_entity(cur=cur,\n",
    "                                         users_from=users_from,\n",
    "                                         users_till=users_till)\n",
    "print(\"Cohorts entity built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Users entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users entity built\n"
     ]
    }
   ],
   "source": [
    "user_details = utils_bux.build_users_entity(cur=cur,\n",
    "                                            users_from=users_from,\n",
    "                                            users_till=users_till,\n",
    "                                            interval=interval,\n",
    "                                            cohorts=cohorts,\n",
    "                                            cohort_size=cohort_size)\n",
    "print(\"Users entity built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transactions entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions entity built\n"
     ]
    }
   ],
   "source": [
    "daily_transactions = utils_bux.build_transactions_entity(cur=cur,\n",
    "                                                         interval=interval)\n",
    "print(\"Transactions entity built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target values built\n"
     ]
    }
   ],
   "source": [
    "labels = utils_bux.build_target_values(cur=cur,\n",
    "                                       medium_value=medium_value,\n",
    "                                       high_value=high_value)\n",
    "print(\"Target values built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE THE ENTITY SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# entities\n",
    "# cohorts = pd.read_csv(\"data/cohorts.csv\")\n",
    "# user_details = pd.read_csv(\"data/users_1y_6mCustomerValue_2000_3w.csv\")\n",
    "# daily_transactions = pd.read_csv('data/cube_1y_6mCustomerValue_2000_3w.csv')\n",
    "\n",
    "# target values\n",
    "# labels = pd.read_csv('data/curcv_1y_6mCustomerValue_2000_3w.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: bux_clv\n",
       "  Entities:\n",
       "    transactions (shape = [28144, 18])\n",
       "    cohorts (shape = [5, 11])\n",
       "    users (shape = [3354, 37])\n",
       "  Relationships:\n",
       "    users.cohort_id -> cohorts.cohort_id\n",
       "    transactions.user_id -> users.user_id"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# problem with the fillna (initial deposit lim and days to initial deposit)\n",
    "es = utils_bux.create_bux_entity_set(cohorts, user_details, daily_transactions)\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE ENGINEERING (DFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features: 527it [00:00, 1731.49it/s]\n",
      "Progress: 100%|██████████| 1/1 [01:04<00:00, 64.61s/cutoff time]\n",
      "303 features generated\n"
     ]
    }
   ],
   "source": [
    "from featuretools.primitives import (Sum, Std, Max, Min, Mean,\n",
    "                                 Count, PercentTrue, NUnique, \n",
    "                                 Day, Week, Month, Weekday, Weekend)\n",
    "\n",
    "\n",
    "trans_primitives = [Day, Week, Month, Weekday, Weekend]\n",
    "agg_primitives = [Sum, Std, Max, Min, Mean, Count, PercentTrue, NUnique]\n",
    "\n",
    "\n",
    "\n",
    "fm_encoded, features_encoded = utils.calculate_feature_matrix_unparallel(es,\n",
    "                                                                         \"users\",\n",
    "                                                                         trans_primitives=trans_primitives,\n",
    "                                                                         agg_primitives=agg_primitives,\n",
    "                                                                         max_depth=2)\n",
    "X = fm_encoded.reset_index().merge(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING AND PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Feature: <Feature: MONTH(ams_first_funded_dts) = unknown>, 0.079\n",
      "2: Feature: <Feature: SUM(transactions.view_position)>, 0.060\n",
      "3: Feature: <Feature: STD(transactions.trades_sb_invested_amount)>, 0.056\n",
      "4: Feature: <Feature: Banner Clicked_hours_till_event>, 0.043\n",
      "5: Feature: <Feature: network = Organic>, 0.039\n",
      "6: Feature: <Feature: Position Opened_hours_till_event>, 0.036\n",
      "7: Feature: <Feature: MAX(transactions.trades_sb_short)>, 0.032\n",
      "8: Feature: <Feature: COUNT(transactions)>, 0.030\n",
      "9: Feature: <Feature: News Item Opened_hours_till_event>, 0.030\n",
      "10: Feature: <Feature: MAX(transactions.total_session_duration)>, 0.030\n",
      "11: Feature: <Feature: DAY(ams_first_funded_dts) = unknown>, 0.029\n",
      "12: Feature: <Feature: PERCENT_TRUE(transactions.IS_WEEKEND(date))>, 0.026\n",
      "13: Feature: <Feature: WEEKDAY(bux_account_created_dts) = 0>, 0.025\n",
      "14: Feature: <Feature: MEAN(transactions.view_position)>, 0.024\n",
      "15: Feature: <Feature: MONTH(ams_first_funded_dts) = 11.0>, 0.021\n",
      "16: Feature: <Feature: MEAN(transactions.total_session_duration)>, 0.021\n",
      "17: Feature: <Feature: nationality = DE>, 0.020\n",
      "18: Feature: <Feature: WEEK(ams_first_funded_dts) = unknown>, 0.020\n",
      "19: Feature: <Feature: STD(transactions.education_topic_read)>, 0.018\n",
      "20: Feature: <Feature: SUM(transactions.total_session_duration)>, 0.015\n",
      "Features built and the most important features saved\n"
     ]
    }
   ],
   "source": [
    "# define the labels based on the prediction problem type\n",
    "X, y = utils.make_labels(X, prediction_problem_type)\n",
    "# split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = utils.train_test_splitting(X, y)\n",
    "# fit the model\n",
    "model = utils.xgboost_train(X_train, y_train, prediction_problem_type)\n",
    "# predict on the testing set\n",
    "y_pred = utils.xgboost_predict(model, X_test, prediction_problem_type)\n",
    "# extract the most important features\n",
    "top_features = utils.feature_importances(model, features_encoded, n=number_of_features)\n",
    "# save the top features\n",
    "ft.save_features(top_features, \"top_features\")\n",
    "print(\"Features built and the most important features saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "if save_model == True:\n",
    "    joblib.dump(model, 'models/model.pkl')\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report shown\n"
     ]
    }
   ],
   "source": [
    "if show_report == True:\n",
    "    # execute the report\n",
    "    print(\"Report shown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_round_xgb = [1 if value > 0.5 else 0 for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def plot_roc_curve(y_test, y_pred):\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.title('ROC curve, AUC: ' + str(auc))\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "plot_roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred.round(0))\n",
    "utils.plot_confusion_matrix(cm, ['Non-whale', 'Whale'], title='Customer lifetime value prediction (Confusion matrix)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X, y, cv=5, scoring='f1')\n",
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
